async function initWebGPU() {
  if (!navigator.gpu) {
    console.error("WebGPU is not supported in this browser.");
    return;
  }
  // get adapter if available
  const adapter = await navigator.gpu.requestAdapter();
  // if webgpu adapter is found, log its details
  if (!adapter) {
    console.error("No WebGPU adapter found.");
    return;
  } else {
    try {
      const adapter = await navigator.gpu.requestAdapter();
      if (!adapter) {
        console.log("No appropriate GPUAdapter found.");
        return;
      }
      console.log("GPU Architecture:", adapter.info.architecture);
      console.log("GPU Supported Features:", adapter.info.description);
      console.log("GPU Supported Limits:", adapter.info.device);
      console.log("GPU Vendor:", adapter.info.vendor);
    } catch (error) {
      console.error("Error requesting WebGPU adapter:", error);
    }
  }
  // get device from adapter
  const device = await adapter.requestDevice();
  console.log("Device: ", device);
  ////////////////////////
  // create shader module
  const module = device.createShaderModule({
    label: "doubling compute module",
    code: `
      @group(0) @binding(0) var<storage, read_write> data: array<f32>;
 
      @compute @workgroup_size(1) fn computeSomething(
        @builtin(global_invocation_id) id: vec3u
      ) {
        let i = id.x;
        data[i] = data[i] * 7.0;
      }
    `,
  });
  ////////////////////////
  // create compute pipeline
  const pipeline = device.createComputePipeline({
    label: "doubling compute pipeline",
    layout: "auto",
    compute: {
      module,
    },
  });

  const input = new Float32Array([1, 3, 5]);
  ////////////////////////
  // create a buffer on the GPU to hold our computation
  // input and output
  const workBuffer = device.createBuffer({
    label: "work buffer",
    size: input.byteLength,
    usage:
      GPUBufferUsage.STORAGE |
      GPUBufferUsage.COPY_SRC |
      GPUBufferUsage.COPY_DST,
  });
  // Copy our input data to that buffer
  device.queue.writeBuffer(workBuffer, 0, input);
  ////////////////////////
  // create a buffer on the GPU to get a copy of the results
  const resultBuffer = device.createBuffer({
    label: "result buffer",
    size: input.byteLength,
    usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
  });
  ////////////////////////
  // Setup a bindGroup to tell the shader which
  // buffer to use for the computation
  const bindGroup = device.createBindGroup({
    label: "bindGroup for work buffer",
    layout: pipeline.getBindGroupLayout(0),
    entries: [{ binding: 0, resource: { buffer: workBuffer } }],
  });
  ////////////////////////
  // Encode commands to do the computation
  const encoder = device.createCommandEncoder({
    label: "doubling encoder",
  });
  const pass = encoder.beginComputePass({
    label: "doubling compute pass",
  });
  pass.setPipeline(pipeline);
  pass.setBindGroup(0, bindGroup);
  pass.dispatchWorkgroups(input.length);
  pass.end();
  // Encode a command to copy the results to a mappable buffer.
  encoder.copyBufferToBuffer(workBuffer, 0, resultBuffer, 0, resultBuffer.size);
  // Finish encoding and submit the commands
  const commandBuffer = encoder.finish();
  device.queue.submit([commandBuffer]);
  // Read the results
  await resultBuffer.mapAsync(GPUMapMode.READ);
  const result = new Float32Array(resultBuffer.getMappedRange().slice());
  resultBuffer.unmap();

  console.log("input", input);
  console.log("result", result);
}

// ... after context configuration (in render.js file, so that needs to be first script in index.html)...

initWebGPU();
